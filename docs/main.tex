\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsfonts}
\usepackage{amsmath}

\title{Projeto de Programação Não Linear}
\author{Vinicius Barcellos\\Samuel Kutz \\Marcelo Baptista \\Matheus Morishita}
\date{}

\begin{document}

\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
            
        \Huge
        \textbf{Projeto de Programação Não Linear}
            
        \vspace{0.5cm}
        \LARGE
        Support Vector Machine (SVM)
            
        \vspace{0.8cm}
        \textbf{Alunos:}\\
        Vinicius Barcellos\\Samuel Kutz\\Matheus Morishita\\Marcelo Baptista
            
        \vfill
        2º Semestre de 2023\\ 
        \vfill
        \includegraphics[width=0.3\textwidth]{ufpr_1000.jpg}
            
            
    \end{center}
\end{titlepage}

\section{Introdução}
No contexto de Machine Learning, modelos podem ser usados para dois tipos de problemas, \textit{Regressão} ou \textit{Classificação}. Em nosso trabalho, estaremos lidando com um modelo de Classificação, as \textbf{Máquinas de Vetores de Suporte} (SVM, do inglês \textit{Support Vector Machine}).

A idéia por trás desse modelo é dividir um conjunto de dados em dois grupos que o modelo considerar distintos. 

Vale ressaltar que esse modelo é de aprendizado não supervisionado, o que basicamente significa que o modelo vai tentar resolver o problema sózinho, e não sabemos se o que ele gerou esta certo ou não.


\section{O problema}
O meio pelo qual \textbf{SVM} tenta atingir o objetivo de classificar os dados é encontrando um \textit{Hyperplano} que vai estar entre os dados de uma forma que, dados "acima" do hyperplano pertencem a um grupo enqunato que dados "abaixo" pertencem a outro, ou seja, teremos uma resposta binária, i.e. \(y_i\in\{-1,1\}\).

O problema surge do fato de que poderiamos ter infinítos hyperplanos entre os dados que poderiam dividi-los, ou seja, precisamos tentar encontrar o hyperplano ótimo, que melhor divide os dados.

\subsection{Fundamentação Teórica}
Support Vector Machine (\textit{SVM}) é um modelo de classificação.
O objetivo do modelo é encontrar um \textit{hiperplano} que passa entre os pontos de um dataset, de maneira a separa-los, para isso o método utiliza-se de modelos de otimização para encontrar o "melhor" hiperplano possível, i.e. o \textit{hiperplano ótimo}. 

Os pontos mais importantes são aqueles mais próximos do hiperplano, portanto, todos os pontos que não estão pertos não são levados em conta. Esses pontos que são levados em consideração são chamados \textit{Vetores de Suporte}, pois apenas eles que ajudam na busca pelo hiperplano ótimo.

Os tipos de pontos que estaremos lidando em nossos problemas serão do tipo:
\[\Omega =\{(x_i,y_i)\subset\mathbb{R}^{p}\times\{-1,1\};i=1,2,\cdots,n\}\]

Ou seja, como teremos apenas dois grupos, \(y_i\) pode apenas pertencer a \(\{-1,1\}\).

\paragraph{Hiperplano} \hspace{0pt}\\

Para o \(\mathbb{R}^2\) uma reta pode ser escrito como:
\[y=ax+b\rightarrow ax+by=c\]

Para o \(\mathbb{R}^3\) teriamos um plano, que pode ser escrito da forma:
\[ax+by+cz=d\]

Para generalizar para \(n\) dimensões poderiamos escrever um hiperplano da forma:
\[w_0+w_1x_1+w_2x_2+\cdots+w_nx_n=0\]

Chamando \(w_0=b\) teriamos:
\[w_1x_1+w_2x_2+\cdots+w_nx_n+b=0\]

que também pode ser escrito da forma vetorial como:
\[w^Tx+b=0\equiv <w,x>+b=0\]

onde \(w,x\in\mathbb{R}^n\) e \(b\in\mathbb{R}\)

\paragraph{Quando eu sei que o Hiperplano Separa os Dois Conjuntos?}\hspace{0pt}\\

Quando um conjunto de pontos está "acima" do hyperplano, ele pertence a um grupo, quando está "abaixo" do hyperplano, ele pertence a outro. 
Como o conceito de "cima" e "baixo" não é tão intuitivo em \(n\) dimensões, podemos escrever matemáticamente como:
\begin{equation}
    \begin{cases}
        w^Tx_i+b>0 &\text{p/ } y_i=1 \\w^Tx_i+b<0 &\text{p/ } y_i=-1
    \end{cases}
\end{equation}


\subsection{Modelagem Matemática}

 Considere um hiperplano que separe os ponto no espaço:
\[w^Tx+b=0\]

nós queremos a \textit{Margem Máxima} entre o hiperplano e os pontos perto do hiperplano, ou sejá, queremos \textit{Maximizar} a distância entre os pontos e o plano. Assim teremos que:

\begin{align}
    (w^Tx_i)+b\geq 1 &\text{ se } y_i=1 \\
    (w^Tx_i)+b\leq -1 &\text{ se } y_i=-1
\end{align}

Queremos que a distância entre os pontos onde \(y_i=1\) e \(y_i=-1\) seja igual, portanto pegamos a distância entre(2) e (3) como:

\[\frac{2}{\|w\|}= \frac{2}{\sqrt{w^Tw}}\]

ou seja, podemos modelar esse problema como:
\[\max_{w,b}\frac{2}{\|w\|}\]

porém, minimizar um elemento que está no denominador pode ser problemático númericamente, portanto podemos considerar o caso \textit{Dual}, ou seja:
\[\max_{w,b}\frac{2}{\|w\|}\equiv \min_{w,b}\frac{w^Tw}{2}\]

portanto, o problema de otimização que teremos de resolver será:


\subsection{Escolha de Algorítimo}

\section{Experimentos Numéricos}
\subsection{O algorítimo Implementado}
\subsection{Resultados Obtidos}

\section{Conclusões}
%\begin{equation}
%\begin{aligned}
%\min_{w,b,\xi} \quad & \frac{1}{2}w^{t}w+C\sum_{i=1}^{N}{\xi_{i}}\\
%\textrm{s.t.} \quad & y_{i}(w\phi(x_{i}+b))+\xi_{i}-1\\
%  &\xi\geq0    \\
%\end{aligned}
%\end{equation}
\end{document}
